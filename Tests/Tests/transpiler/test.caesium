import grammar
import tokenizer

Int main(Vector<String> ref args):
	auto w = Word{0, "hi"}
	auto t1 = Or<Word, Int>{ Word{ "t1", 1 } }
	Or<Word, Int> t2 = Word{ 't2', 2 }
	auto program = "Int f():\n\treturn 0\n\nInt main(Vector<String> ref args):\n\treturn f()\n"
	auto tokens = Tokenizer{ program, 0 }.read()
	tokens_and_iterator g = { tokens, 0 }
	println(build(ref file, ref g.it))
	return 0
